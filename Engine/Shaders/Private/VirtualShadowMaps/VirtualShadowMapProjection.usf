// Copyright Epic Games, Inc. All Rights Reserved.

/*=============================================================================
	VirtualShadowMapProjection.usf: 
=============================================================================*/

#define SUPPORT_CONTACT_SHADOWS 1

#include "../Common.ush"
#include "../SceneTexturesCommon.ush"
#include "../DeferredShadingCommon.ush"
#include "../DeferredLightingCommon.ush"
#include "../ScreenSpaceDenoise/SSDPublic.ush"
#include "../ScreenSpaceDenoise/SSDDefinitions.ush"
#include "../ScreenSpaceDenoise/SSDPublicHarmonics.ush"
#include "../LightShaderParameters.ush"
#include "../LightGridCommon.ush"
#include "../HairStrands/HairStrandsVisibilityCommon.ush"
#include "PageAccessCommon.ush"
#include "ProjectionCommon.ush"
#include "ProjectionDirectional.ush"
#include "ProjectionSpot.ush"

#ifndef DIRECTIONAL_LIGHT
#define DIRECTIONAL_LIGHT 0
#endif

#define CONTACT_SHADOW_SAMPLES 8

float4 EncodeLightAttenuationFromMask(float ShadowMask)
{
	const float ShadowFadeFraction = 1;
	float SSSTransmission = ShadowMask;

	// 0 is shadowed, 1 is unshadowed
	// RETURN_COLOR not needed unless writing to SceneColor;
	//float FadedShadow = lerp(1.0f, Square(ShadowMask), ShadowFadeFraction);
	//float FadedSSSShadow = lerp(1.0f, Square(SSSTransmission), ShadowFadeFraction);
	float FadedShadow = lerp(1.0f, ShadowMask, ShadowFadeFraction);
	float FadedSSSShadow = lerp(1.0f, SSSTransmission, ShadowFadeFraction);

	// the channel assignment is documented in ShadowRendering.cpp (look for Light Attenuation channel assignment)
	return EncodeLightAttenuation(half4(FadedShadow, FadedSSSShadow, FadedShadow, FadedSSSShadow));
}

Texture2D<float4> InputSignal;

void VirtualShadowMapCompositePS(
	in float4 SvPosition : SV_Position,
	out float4 OutShadowMask : SV_Target
	)
{
	// NOTE: The signal is encoded as per SSDSignalBufferEncoding.ush, SIGNAL_BUFFER_LAYOUT_PENUMBRA_RECONSTRUCTION
	float4 Input = InputSignal.Load(int3(SvPosition.xy, 0));
	float SampleCount = Input.g;
	float ShadowFactor = Input.r;
	float Shadow = (SampleCount > 0 ? ShadowFactor : 1.0f);
	
	OutShadowMask = EncodeLightAttenuationFromMask(Shadow);
}


SCHEDULER_MIN_PRESSURE
MAX_OCCUPENCY

// Returns hit distance or negative if miss
float VirtualShadowMapScreenRayCast(
	float3 RayOriginTranslatedWorld, float3 RayDirection, float RayLength,
	int NumSteps, float StepOffset)
{
	bool bHitCastContactShadow = true;
	float HitDistance = ShadowRayCast(
		RayOriginTranslatedWorld, RayDirection, RayLength,
		NumSteps, StepOffset, bHitCastContactShadow);

	return (bHitCastContactShadow) ? HitDistance : -1.0f;
}

float ProjectSingleSample(
	int VirtualShadowMapId,
	float3 L,
	float3 TranslatedWorldPosition,
	float3 EstimatedGeoWorldNormal,
	float ContactShadowLengthWorld,
	inout float InOutHitDistance)
{
	float3 WorldPosition = TranslatedWorldPosition - View.PreViewTranslation;

	FVirtualShadowMapSampleResult Sample =
		SampleVirtualShadowMap(VirtualShadowMapId, WorldPosition, ContactShadowLengthWorld, EstimatedGeoWorldNormal);

	if (Sample.bOccluded)
	{
		InOutHitDistance = Sample.OccluderDistance;
	}

	return Sample.ShadowFactor;
}

float4 EncodeOutput(
	float3 TranslatedWorldPosition,
	FLightShaderParameters Light,
	uint LightType,
	float RayMissFactor,
	float HitDistance,
	int SampleCount)
{
	// See signal encoding for SIGNAL_BUFFER_LAYOUT_PENUMBRA_RECONSTRUCTION in SSDSignalBufferEncoding.ush
	// We fuse that logic in here to avoid needing another pass, but it's hard to call the functions directly as they depend on a large
	// number of preprocessor defines and logic that we don't want to mirror here.
	// Unfortunately that means this logic can get out of date when the denoiser changes, but that's the trade-off for now.
	float4 OutputSignal = float4(RayMissFactor, SampleCount, WORLD_RADIUS_MISS, RayMissFactor);
	if (RayMissFactor < 1.0f)
	{
		OutputSignal.z = ComputeLightSampleWorldBluringRadius(TranslatedWorldPosition, LightType, Light, HitDistance);
	}
	return OutputSignal;
}

float3 GetEstimatedGeoWorldNormal(float3 TranslatedWorldPosition, float2 ScreenUV)
{
	// Figure out slope, we do world space since that is the space where we might override using the shading normal...
	float3 TranslatedWorldPositionDDX = DDX(TranslatedWorldPosition);
	float3 TranslatedWorldPositionDDY = DDY(TranslatedWorldPosition);
	float3 EstimatedGeoWorldNormal = cross(TranslatedWorldPositionDDX, TranslatedWorldPositionDDY);

	// Handle NaNs; will cause it to revert to shading normal below
	float LengthSq = dot(EstimatedGeoWorldNormal, EstimatedGeoWorldNormal);
	EstimatedGeoWorldNormal = LengthSq > 1e-8f ? normalize(EstimatedGeoWorldNormal) : float3(0, 0, 0);

#if 1
	// NOTE: Gbuffer normal is not the surface normal for hair; hair lighting takes a different path but possibly
	// necessary to do some sort of special casing here (disable normal offset and biasing entirely?).
	FGBufferData GBufferData = GetGBufferData(ScreenUV);
	// If the estimated geo normal is too far out we assume it's broken (derivative includes other surfaces or background) and fall back to the shading normal
	if (dot(GBufferData.WorldNormal, EstimatedGeoWorldNormal) < 0.25f)
	{
		EstimatedGeoWorldNormal = GBufferData.WorldNormal;
	}
#endif

	return EstimatedGeoWorldNormal;
}

FLightShaderParameters ConvertFromLocal( const FLocalLightData LightData )
{
	FLightShaderParameters Light = (FLightShaderParameters)0;
	Light.Position			= LightData.LightPositionAndInvRadius.xyz;
	Light.InvRadius			= LightData.LightPositionAndInvRadius.w;
	Light.Color				= LightData.LightColorAndFalloffExponent.xyz;
	Light.FalloffExponent	= LightData.LightColorAndFalloffExponent.w;
	Light.Direction			= LightData.LightDirectionAndShadowMask.xyz;
	Light.Tangent			= LightData.LightTangentAndSoftSourceRadius.xyz;
	Light.SpotAngles		= LightData.SpotAnglesAndSourceRadiusPacked.xy;
	Light.SpecularScale		= 1;
	Light.SourceRadius		= LightData.SpotAnglesAndSourceRadiusPacked.z;
	Light.SoftSourceRadius	= LightData.LightTangentAndSoftSourceRadius.w;
	Light.SourceLength		= f16tof32(asuint(LightData.SpotAnglesAndSourceRadiusPacked.w));
	return Light;
}


int4 ProjectionRect;
float ContactShadowLength;
float NormalOffsetWorld;			// Normal offset in world space
int SMRTRayCount;					// 0 = off
int SMRTSamplesPerRay;
float SMRTRayLengthScale;			// Directional lights
float SMRTCotMaxRayAngleFromLight;	// Spot/point lights

// One pass projection
StructuredBuffer< int > VirtualShadowMapIdRemap;
uint NumDirectionalLightSmInds;
RWTexture2D< uint > RWShadowMaskBits;

// Single light per pass
// Light parameters loaded via GetRootLightShaderParameters();
int LightUniformVirtualShadowMapId;
RWTexture2D< float4 > RWSignal;

// Type of input data consume by the page allocation (i.e., data read from the source buffer: Gbuffer, HairStrands data, ...)
#define INPUT_TYPE_GBUFFER 0
#define INPUT_TYPE_HAIRSTRANDS 1
uint InputType;

struct FProjectLightResult
{
	half ShadowFactor;
	// NOTE: The signal is encoded as per SSDSignalBufferEncoding.ush, SIGNAL_BUFFER_LAYOUT_PENUMBRA_RECONSTRUCTION
	float4 Signal;
};

FProjectLightResult ProjectLight(
	int VirtualShadowMapId,
	FLightShaderParameters Light,
	uint2 PixelPos,
	float SceneDepth,
	float ContactShadowLengthWorld,
	float3 TranslatedWorldPosition,
	half3 GBufferNormal,
	const half Noise)
{
	const float3 WorldPosition = TranslatedWorldPosition - View.PreViewTranslation;

#if DIRECTIONAL_LIGHT
	uint LightType = LIGHT_TYPE_DIRECTIONAL;
	float3 L = Light.Direction;
	// TODO: Find a way to branch out backfacing surfaces again that doesn't make assumptions
	// about the Gbuffer normal that break with hair
	bool bInLightRegion = true;
#else
	uint LightType = Light.SpotAngles.x > -2.0f ? LIGHT_TYPE_SPOT : LIGHT_TYPE_POINT;
	float3 ToLight = Light.Position - WorldPosition;
	float d2 = dot( ToLight, ToLight );
	float InvDist = rsqrt( d2 );
	half3 L = ToLight * InvDist;
	
	bool bInLightRadius = InvDist >= Light.InvRadius;
	bool bInLightCone = dot( L, Light.Direction ) >= Light.SpotAngles.x;
	bool bInLightRegion = bInLightRadius && bInLightCone;
	
#endif // DIRECTIONAL_LIGHT

	float ShadowFactor = 1.0f;
	float HitDistance = WORLD_RADIUS_MISS;
	uint SampleCount = 0;

	BRANCH
	if (bInLightRegion)
	{
		const bool bIsHair = InputType == INPUT_TYPE_HAIRSTRANDS;
		const half3 EstimatedGeoWorldNormal = bIsHair ? L : GBufferNormal;

		float3 OffsetTranslatedWorldPosition = TranslatedWorldPosition + EstimatedGeoWorldNormal * NormalOffsetWorld;

		if (SMRTRayCount > 0)
		{
			SampleCount = SMRTRayCount;
		#if DIRECTIONAL_LIGHT
			ShadowFactor = TraceDirectional(
				VirtualShadowMapId,
				Light,
				PixelPos,
				SceneDepth,
				OffsetTranslatedWorldPosition,
				ContactShadowLengthWorld,
				SMRTRayCount,
				SMRTSamplesPerRay,
				SMRTRayLengthScale,
				Noise,
				/* out */ HitDistance);
		#else
			ShadowFactor = TraceLocalLight(
				VirtualShadowMapId,
				Light,
				LightType,
				PixelPos,
				SceneDepth,
				OffsetTranslatedWorldPosition,
				ContactShadowLengthWorld,
				SMRTRayCount,
				SMRTSamplesPerRay,
				SMRTCotMaxRayAngleFromLight,
				Noise,
				/* out */ HitDistance);
		#endif // DIRECTIONAL_LIGHT
		}
		else
		{
			SampleCount = 1;
			ShadowFactor = ProjectSingleSample(
				VirtualShadowMapId,
				L,
				OffsetTranslatedWorldPosition,
				EstimatedGeoWorldNormal,
				ContactShadowLengthWorld,
				HitDistance);
		}

		if (ContactShadowLengthWorld > 0.0f)
		{
			half ContactShadowHitDistance = VirtualShadowMapScreenRayCast(TranslatedWorldPosition, L, ContactShadowLengthWorld, CONTACT_SHADOW_SAMPLES, Noise);		
			if (ContactShadowHitDistance >= 0.0f)
			{
				ShadowFactor = 0.0f;
				HitDistance = ContactShadowHitDistance;
			}
		}
	}

	FProjectLightResult Result;
	Result.ShadowFactor = ShadowFactor;
	Result.Signal = EncodeOutput(TranslatedWorldPosition, Light, LightType, ShadowFactor, HitDistance, SampleCount);
	return Result;
}

[numthreads(8, 8, 1)]
void VirtualShadowMapProjection(
	uint3	GroupId				: SV_GroupID,
	uint	GroupIndex			: SV_GroupIndex,
	uint3	DispatchThreadId	: SV_DispatchThreadID )
{
	// Morton order within a group so page access/atomics are more coherent and wave-swizzled gradients are possible.
	uint2 PixelCoord = DispatchThreadId.xy;
	uint2 LocalPixelPos = 8 * GroupId.xy + MortonDecode( GroupIndex );
	uint2 PixelPos = LocalPixelPos + uint2( ProjectionRect.xy );
	if ( any( PixelPos >= uint2( ProjectionRect.zw ) ) )
	{
		return;
	}
	
	float DeviceZ = SceneTexturesStruct.SceneDepthTexture.Load( int3( PixelPos, 0 ) ).r;
	if (InputType == INPUT_TYPE_HAIRSTRANDS)
	{
		FCategorizationData CatData = DecodeCategorizationData(HairStrands.HairCategorizationTexture.Load( int3(PixelPos, 0 ) ) );
		DeviceZ = CatData.ClosestDepth;
		if (CatData.PixelCoverage < 0)
		{
			return;
		}
	}
	const float SceneDepth = ConvertFromDeviceZ( DeviceZ );

	const float4 SvPosition = float4( float2( PixelPos ) + 0.5, DeviceZ, 1.0f );
	const float3 TranslatedWorldPosition = SvPositionToTranslatedWorld( SvPosition );

	const float ContactShadowLengthWorld = ContactShadowLength * View.ClipToView[1][1] * SceneDepth;
	const half Noise = InterleavedGradientNoise( SvPosition.xy, View.StateFrameIndexMod8 );

	const half3 GBufferNormal = GetGBufferDataUint( PixelPos, true ).WorldNormal;
		
#if ONE_PASS_PROJECTION
	uint EyeIndex = 0; // TODO: Instanced stereo
	uint GridLinearIndex = ComputeLightGridCellIndex( LocalPixelPos, SceneDepth, EyeIndex );
	const FCulledLightsGridData CulledLightGridData = GetCulledLightsGrid( GridLinearIndex, EyeIndex );

	// We can only handle 10 lights in our output encoding right now, so no purpose in computing more
	const uint LightCount = min( 10, CulledLightGridData.NumLocalLights );

	uint ShadowMask = 0xffffffff;

	LOOP
	for (uint Index = 0; Index < LightCount; ++Index)
	{
		// The Virtual Shadow Remap stores directional lights first
		const uint LocalLightIndex = ForwardLightData.CulledLightDataGrid[CulledLightGridData.DataStartIndex + Index];
		int VirtualShadowMapId = VirtualShadowMapIdRemap[VirtualShadowMap.NumDirectionalLights + LocalLightIndex];

		if (VirtualShadowMapId != INDEX_NONE)
		{
			const FLocalLightData LightData = GetLocalLightData( CulledLightGridData.DataStartIndex + Index, EyeIndex );
			FLightShaderParameters Light = ConvertFromLocal( LightData );

			FProjectLightResult Result = ProjectLight(
				VirtualShadowMapId,
				Light,
				PixelPos,
				SceneDepth,
				ContactShadowLengthWorld,
				TranslatedWorldPosition,
				GBufferNormal,
				Noise);

			ShadowMask ^= ( ~uint( round( Result.ShadowFactor * 7.0 ) ) & 7 ) << (Index*3);
		}
	}

	RWShadowMaskBits[ PixelPos ] = ~ShadowMask;

#else // !ONE_PASS_PROJECTION
	int VirtualShadowMapId = LightUniformVirtualShadowMapId;
	FLightShaderParameters Light = GetRootLightShaderParameters();

	FProjectLightResult Result = ProjectLight(
		VirtualShadowMapId,
		Light,
		PixelPos,
		SceneDepth,
		ContactShadowLengthWorld,
		TranslatedWorldPosition,
		GBufferNormal,
		Noise);

	RWSignal[ PixelPos ] = Result.Signal;
#endif // ONE_PASS_PROJECTION
}
