// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "../MonteCarlo.ush"
#include "../BlueNoise.ush"
#include "../SceneTextureParameters.ush"

//Note: Also have to change format on C++ side
#define SH_QUANTIZE_DIRECTIONAL_COEFFICIENTS 0
#define PROBE_THREADGROUP_SIZE_2D 8
#define PROBE_THREADGROUP_SIZE_1D 64

// Main control for Screen Probe tracing resolution.  8 = 8x8 traces per probe
uint ScreenProbeTracingOctahedronResolution;
// Screen probe traces are re-sampled to this resolution before filtering / BRDF integration
uint ScreenProbeGatherOctahedronResolution;
uint ScreenProbeGatherOctahedronResolutionWithBorder;

// Size of the downsampled viewport, in probes.  This corresponds to the uniform placement viewport.
uint2 ScreenProbeViewSize;

// Size of the active viewport into the atlas, in probes
uint2 ScreenProbeAtlasViewSize;
// Size of all the probe atlas textures, in probes
uint2 ScreenProbeAtlasBufferSize;

float ScreenProbeGatherMaxMip;
float RelativeSpeedDifferenceToConsiderLightingMoving;
float ScreenTraceNoFallbackThicknessScale;

// Downsample factor from full res to Screen Probe res
uint ScreenProbeDownsampleFactor;
// ScreenProbeViewSize.x * ScreenProbeViewSize.y
uint NumUniformScreenProbes;
uint MaxNumAdaptiveProbes;
int FixedJitterIndex;

// Screen Probe GBuffers.  These are indexed by ScreenProbeAtlasCoord and adaptive probes are placed at the bottom of the texture.
// Note: negative if unlit
Texture2D<uint> ScreenProbeSceneDepth;
Texture2D ScreenProbeWorldSpeed;

// Single element, contains the number of adaptive screen probes placed
Buffer<uint> NumAdaptiveScreenProbes;
Buffer<uint> AdaptiveScreenProbeData;

Texture2D<uint> ScreenTileAdaptiveProbeHeader;
Texture2D<uint> ScreenTileAdaptiveProbeIndices;

#define SCREEN_TEMPORAL_INDEX			(FixedJitterIndex < 0 ? View.StateFrameIndexMod8 : FixedJitterIndex)
#define RAY_DIRECTION_TEMPORAL_INDEX	(FixedJitterIndex < 0 ? View.StateFrameIndex : FixedJitterIndex)
#define GENERAL_TEMPORAL_INDEX			(FixedJitterIndex < 0 ? View.StateFrameIndexMod8 : FixedJitterIndex)

// Returns the jitter offset in the range [0, ScreenProbeDownsampleFactor - 1]
uint2 GetScreenTileJitter(uint TemporalIndex)
{
	return Hammersley16(TemporalIndex, 8, 0) * ScreenProbeDownsampleFactor;
}

float2 GetProbeTexelCenter(uint2 ScreenTileCoord)
{
#define JITTER_RAY_DIRECTION 1
#if JITTER_RAY_DIRECTION
	#define BLUE_NOISE_LUT 1
	#if BLUE_NOISE_LUT
		return EvalBlueNoise(ScreenTileCoord % BlueNoise.Dimensions.xy, RAY_DIRECTION_TEMPORAL_INDEX % BlueNoise.Dimensions.z).xy;
	#else
		uint2 RandomSeed = Rand3DPCG16(int3(ScreenTileCoord, 0)).xy;
		return Hammersley16(RAY_DIRECTION_TEMPORAL_INDEX % 8, 8, RandomSeed);
	#endif
#else
	return float2(0.5, 0.5);
#endif
}

// Note: Returns negative depth for invalid probe
float GetScreenProbeDepth(uint2 ScreenProbeAtlasCoord)
{
	return asfloat(ScreenProbeSceneDepth[ScreenProbeAtlasCoord]);
}

uint GetNumAdaptiveScreenProbes()
{
	return min(NumAdaptiveScreenProbes[0], MaxNumAdaptiveProbes);
}

uint2 GetAdaptiveProbeCoord(uint2 ScreenTileCoord, uint AdaptiveProbeListIndex)
{
	uint2 AdaptiveProbeCoord = uint2(AdaptiveProbeListIndex % ScreenProbeDownsampleFactor, AdaptiveProbeListIndex / ScreenProbeDownsampleFactor);
	//return ScreenTileCoord * ScreenProbeDownsampleFactor + AdaptiveProbeCoord;
	return AdaptiveProbeCoord * ScreenProbeViewSize + ScreenTileCoord;
}

uint GetNumScreenProbes()
{
	return NumUniformScreenProbes + GetNumAdaptiveScreenProbes();
}

uint EncodeScreenProbeData(uint2 ScreenProbeScreenPosition)
{
	return (ScreenProbeScreenPosition.x & 0xFFFF) | ((ScreenProbeScreenPosition.y & 0xFFFF) << 16);
}

uint2 DecodeScreenProbeData(uint EncodedProbeData)
{
	return uint2(EncodedProbeData & 0xFFFF, (EncodedProbeData >> 16) & 0xFFFF);
}

// Note this can return a screen position outside of the valid viewport, since probes can be placed off-screen due to DivideAndRoundUp
uint2 GetScreenProbeScreenPosition(uint ScreenProbeIndex)
{
	uint2 ScreenProbeAtlasCoord = uint2(ScreenProbeIndex % ScreenProbeViewSize.x, ScreenProbeIndex / ScreenProbeViewSize.x);
	uint2 ScreenProbeScreenPosition = ScreenProbeAtlasCoord * ScreenProbeDownsampleFactor + GetScreenTileJitter(SCREEN_TEMPORAL_INDEX) + (uint2)View.ViewRectMin.xy;

	if (ScreenProbeIndex >= NumUniformScreenProbes)
	{
		ScreenProbeScreenPosition = DecodeScreenProbeData(AdaptiveScreenProbeData[ScreenProbeIndex - NumUniformScreenProbes]);
	}

	return ScreenProbeScreenPosition;
}

uint2 GetScreenTileCoord(uint2 ScreenProbeScreenPosition)
{
	return (ScreenProbeScreenPosition - GetScreenTileJitter(SCREEN_TEMPORAL_INDEX) - (uint2)View.ViewRectMin.xy) / ScreenProbeDownsampleFactor;
}

uint2 GetUniformScreenProbeScreenPosition(uint2 ScreenTileCoord)
{
	return ScreenTileCoord * ScreenProbeDownsampleFactor + GetScreenTileJitter(SCREEN_TEMPORAL_INDEX) + (uint2)View.ViewRectMin.xy;
}

float2 GetScreenTileCoordFromScreenUV(float2 ScreenUV, uint TemporalIndex)
{
	return (ScreenUV - (View.ViewRectMin.xy + GetScreenTileJitter(TemporalIndex) + 0.5f) * View.BufferSizeAndInvSize.zw) / (ScreenProbeDownsampleFactor * View.BufferSizeAndInvSize.zw);
}

float2 GetScreenUVFromScreenTileCoord(uint2 ScreenTileCoord)
{
	uint2 ScreenProbeScreenPosition = ScreenTileCoord * ScreenProbeDownsampleFactor + GetScreenTileJitter(SCREEN_TEMPORAL_INDEX) + (uint2)View.ViewRectMin.xy;
	return (ScreenProbeScreenPosition + .5f) * View.BufferSizeAndInvSize.zw;
}

float2 GetScreenUVFromScreenProbePosition(uint2 ScreenProbeScreenPosition)
{
	// Probe ScreenUV can be outside of valid viewport, since probes are downsampled with DivideAndRoundUp
	float2 ScreenCoord = min((float2)ScreenProbeScreenPosition, View.ViewRectMin.xy + View.ViewSizeAndInvSize.xy - 1.0f);
	return (ScreenCoord + .5f) * View.BufferSizeAndInvSize.zw;
}

float3 GetWorldPositionFromScreenUV(float2 ScreenUV, float SceneDepth)
{
	float2 ScreenPosition = (ScreenUV - View.ScreenPositionScaleBias.wz) / View.ScreenPositionScaleBias.xy;
	float3 WorldPosition = mul(float4(ScreenPosition * SceneDepth, SceneDepth, 1), View.ScreenToWorld).xyz;
	return WorldPosition;
}

float3 GetHistoryScreenPosition(float2 ScreenPosition, float2 ScreenUV, float DeviceZ)
{
	float3 HistoryScreenPosition = float3(ScreenPosition, DeviceZ);
	bool bIsDynamicPixel = false;

	{
		float4 ThisClip = float4(HistoryScreenPosition, 1);
		float4 PrevClip = mul(ThisClip, View.ClipToPrevClip);
		float3 PrevScreen = PrevClip.xyz / PrevClip.w;
		float3 Velocity = HistoryScreenPosition - PrevScreen;
		float4 EncodedVelocity = GBufferVelocityTexture.SampleLevel(GlobalPointClampedSampler, ScreenUV, 0);
		bIsDynamicPixel = EncodedVelocity.x > 0.0;

		if (bIsDynamicPixel)
		{
			Velocity = DecodeVelocityFromTexture(EncodedVelocity);
		}

		HistoryScreenPosition -= Velocity;
	}

	return HistoryScreenPosition;
}

float3 GetPrevTranslatedWorldPosition(float3 HistoryScreenPosition)
{
	float HistorySceneDepth = ConvertFromDeviceZ(HistoryScreenPosition.z);
	float3 PrevPositionTranslatedWorld = mul(float4(HistoryScreenPosition.xy * HistorySceneDepth, HistorySceneDepth, 1), View.PrevScreenToTranslatedWorld).xyz;
	float3 PrevTranslatedWorldPosition = PrevPositionTranslatedWorld + (View.PreViewTranslation - View.PrevPreViewTranslation);
	return PrevTranslatedWorldPosition;
}

uint2 GetTraceBufferCoord(uint2 ScreenProbeAtlasCoord, uint2 TraceTexelCoord)
{
	#define DEINTERLEAVED_TRACE_BUFFER_STORAGE 0
	#if DEINTERLEAVED_TRACE_BUFFER_STORAGE
		return TraceTexelCoord * ScreenProbeAtlasViewSize + ScreenProbeAtlasCoord;
	#else
		return ScreenProbeAtlasCoord * ScreenProbeTracingOctahedronResolution + TraceTexelCoord;
	#endif
}

RWTexture2D<uint> RWTraceHit;
RWTexture2D<float3> RWTraceRadiance;
Texture2D<uint> TraceHit;

float GetProbeMaxHitDistance()
{
	return MaxHalfFloat;

}

uint EncodeProbeRayDistance(float HitDistance, bool bHit, bool bMoving)
{
	return f32tof16(HitDistance) | (bHit ? (1 << 17) : 0) | (bMoving ? (1 << 18) : 0);
}

float DecodeProbeRayDistance(uint Encoded, out bool bHit, out bool bMoving)
{
	bHit = (Encoded & (1 << 17)) != 0;
	bMoving = (Encoded & (1 << 18)) != 0;
	return f16tof32(Encoded & 0xFFFF);
}

float DecodeProbeRayDistance(uint Encoded, out bool bHit)
{
	bool bMoving;
	return DecodeProbeRayDistance(Encoded, bHit, bMoving);
}

float DecodeProbeRayDistance(uint Encoded)
{
	bool bHit;
	bool bMoving;
	return DecodeProbeRayDistance(Encoded, bHit, bMoving);
}

float EncodeProbeHitDistanceForFiltering(float HitDistance)
{
	// Encode one negative value to indicate invalid ray
	return sqrt(HitDistance / GetProbeMaxHitDistance()) * 254.0f / 255.0f + 1.0f / 255.0f;
}

float DecodeProbeHitDistanceForFiltering(float Encoded)
{
	float Linear = Encoded * Encoded * GetProbeMaxHitDistance();
	return (Linear - 1.0f / 255.0f) * 255.0f / 254.0f;
}

// Stores a packed ray info for each tracing shader lane storing the direction and mip level of the ray to trace
Texture2D<uint> StructuredImportanceSampledRayInfosForTracing;
uint MaxImportanceSamplingOctahedronResolution;
uint ScreenProbeBRDFOctahedronResolution;

#define INVALID_TRACING_COORD 0xFE

uint PackRayInfo(uint2 TexelCoord, uint Level)
{
	// Pack in 16 bits
	return (TexelCoord.x & 0x3F) | ((TexelCoord.y & 0x3F) << 6) | ((Level & 0xF) << 12);
}

void UnpackRayInfo(uint RayInfo, out uint2 TexelCoord, out uint Level)
{
	TexelCoord.x = RayInfo & 0x3F;
	TexelCoord.y = (RayInfo >> 6) & 0x3F;
	Level = (RayInfo >> 12) & 0xF;
}

void GetProbeTracingUV(
	uint2 ScreenProbeAtlasCoord,
	uint2 TracingTexelCoord,
	float2 ProbeTexelCenter,
	float NumSupersamples,
	out float2 ProbeUV,
	out float ConeHalfAngle)
{
#if STRUCTURED_IMPORTANCE_SAMPLING
	uint2 GlobalTraceCoord = GetTraceBufferCoord(ScreenProbeAtlasCoord, TracingTexelCoord);
	uint RayInfo = StructuredImportanceSampledRayInfosForTracing[GlobalTraceCoord];
	uint2 RayTexelCoord;
	uint RayLevel;
	UnpackRayInfo(RayInfo, RayTexelCoord, RayLevel);

	uint MipSize = MaxImportanceSamplingOctahedronResolution >> RayLevel;
	float InvSupersampledMipSize = 1.0f / (MipSize * NumSupersamples);
	ProbeUV = (RayTexelCoord * NumSupersamples + ProbeTexelCenter) * InvSupersampledMipSize;
	ConeHalfAngle = acosFast(1.0f - 1.0f * InvSupersampledMipSize * InvSupersampledMipSize);

#else
	ProbeUV = (TracingTexelCoord * NumSupersamples + ProbeTexelCenter) / float(ScreenProbeTracingOctahedronResolution * NumSupersamples);
	// Evenly distributing the sphere solid angle among all cones
	ConeHalfAngle = acosFast(1.0f - 1.0f / (float)(ScreenProbeTracingOctahedronResolution * ScreenProbeTracingOctahedronResolution * NumSupersamples * NumSupersamples));
#endif
}

Texture2D OctahedralSolidAngleTexture;
float OctahedralSolidAngleTextureResolutionSq;

float OctahedralSolidAngleLUT(float2 UV, float Resolution)
{
	return OctahedralSolidAngleTexture.SampleLevel(GlobalBilinearClampedSampler, UV, 0).x * OctahedralSolidAngleTextureResolutionSq / (Resolution * Resolution);
}

Buffer<uint> CompactedTraceTexelAllocator;
Buffer<uint2> CompactedTraceTexelData;

uint2 EncodeTraceTexel(uint ScreenProbeIndex, uint2 TraceTexelCoord, float TraceHitDistance)
{
	return uint2(
		(ScreenProbeIndex & 0xFFFFF) | ((TraceTexelCoord.x & 0x1F) << 20) | ((TraceTexelCoord.y & 0x1F) << 25),
		asuint(TraceHitDistance));
}

void DecodeTraceTexel(uint2 TraceTexelData, inout uint ScreenProbeIndex, inout uint2 TraceTexelCoord, inout float TraceHitDistance)
{
	ScreenProbeIndex = TraceTexelData.x & 0xFFFFF;
	TraceTexelCoord.x = (TraceTexelData.x >> 20) & 0x1F;
	TraceTexelCoord.y = (TraceTexelData.x >> 25) & 0x1F;
	TraceHitDistance = asfloat(TraceTexelData.y);
}

Texture2D<uint> LightingChannelsTexture;

bool HasDistanceFieldRepresentation(float2 ScreenUV)
{
	return (LightingChannelsTexture[(int2)(ScreenUV * View.BufferSizeAndInvSize.xy)] & (1 << LIGHTING_CHANNELS_TEXTURE_DISTANCE_FIELD_REPRESENTATION_BIT)) != 0;
}
