// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "../MonteCarlo.ush"
#include "../BlueNoise.ush"
#include "../SceneTextureParameters.ush"

//Note: Also have to change format on C++ side
#define SH_QUANTIZE_DIRECTIONAL_COEFFICIENTS 0
#define PROBE_THREADGROUP_SIZE_2D 8 
#define PROBE_THREADGROUP_SIZE_1D 64

#define PROBE_IRRADIANCE_FORMAT_SH3 0
#define PROBE_IRRADIANCE_FORMAT_OCT 1
#define IRRADIANCE_PROBE_RES 6
#define IRRADIANCE_PROBE_WITH_BORDER_RES (IRRADIANCE_PROBE_RES + 2)

// Main control for Screen Probe tracing resolution.  8 = 8x8 traces per probe
uint ScreenProbeTracingOctahedronResolution;
// Screen probe traces are re-sampled to this resolution before filtering / BRDF integration
uint ScreenProbeGatherOctahedronResolution;
uint ScreenProbeGatherOctahedronResolutionWithBorder;

// Size of the downsampled viewport, in probes.  This corresponds to the uniform placement viewport.
uint2 ScreenProbeViewSize;

// Size of the active viewport into the atlas, in probes
uint2 ScreenProbeAtlasViewSize;
// Size of all the probe atlas textures, in probes
uint2 ScreenProbeAtlasBufferSize;

float ScreenProbeGatherMaxMip;
float RelativeSpeedDifferenceToConsiderLightingMoving;
float ScreenTraceNoFallbackThicknessScale;

// Used by InterpolateFromScreenProbes() to sample probe radiance with border
float2 SampleRadianceProbeUVMul;
float2 SampleRadianceProbeUVAdd;
float2 SampleRadianceAtlasUVMul;

// Downsample factor from full res to Screen Probe res
uint ScreenProbeDownsampleFactor;
// ScreenProbeViewSize.x * ScreenProbeViewSize.y
uint NumUniformScreenProbes;
uint MaxNumAdaptiveProbes;
int FixedJitterIndex;

// Screen Probe GBuffers.  These are indexed by ScreenProbeAtlasCoord and adaptive probes are placed at the bottom of the texture.
// Note: negative if unlit
Texture2D<uint> ScreenProbeSceneDepth;
Texture2D<float2> ScreenProbeWorldNormal;
Texture2D<uint> ScreenProbeWorldSpeed;

// Single element, contains the number of adaptive screen probes placed
StructuredBuffer<uint> NumAdaptiveScreenProbes;
StructuredBuffer<uint> AdaptiveScreenProbeData;

Texture2D<uint> ScreenTileAdaptiveProbeHeader;
Texture2D<uint> ScreenTileAdaptiveProbeIndices;

#define SCREEN_TEMPORAL_INDEX			(FixedJitterIndex < 0 ? View.StateFrameIndexMod8 : FixedJitterIndex)
#define RAY_DIRECTION_TEMPORAL_INDEX	(FixedJitterIndex < 0 ? View.StateFrameIndex : FixedJitterIndex)
#define GENERAL_TEMPORAL_INDEX			(FixedJitterIndex < 0 ? View.StateFrameIndexMod8 : FixedJitterIndex)

// Returns the jitter offset in the range [0, ScreenProbeDownsampleFactor - 1]
uint2 GetScreenTileJitter(uint TemporalIndex)
{
	return Hammersley16(TemporalIndex, 8, 0) * ScreenProbeDownsampleFactor;
	//return R2Sequence(TemporalIndex) * ScreenProbeDownsampleFactor;
}

float2 GetProbeTexelCenter(uint2 ScreenTileCoord)
{
#define JITTER_RAY_DIRECTION 1
#if JITTER_RAY_DIRECTION
	#define BLUE_NOISE_LUT 1
	#if BLUE_NOISE_LUT
		return BlueNoiseVec2(ScreenTileCoord, RAY_DIRECTION_TEMPORAL_INDEX);
	#else
		uint2 RandomSeed = Rand3DPCG16(int3(ScreenTileCoord, 0)).xy;
		return Hammersley16(RAY_DIRECTION_TEMPORAL_INDEX % 8, 8, RandomSeed);
	#endif
#else
	return float2(0.5, 0.5);
#endif
}

// Note: Returns negative depth for invalid probe
float GetScreenProbeDepth(uint2 ScreenProbeAtlasCoord, Texture2D<uint> ProbeSceneDepthTexture)
{
	return asfloat(ScreenProbeSceneDepth[ScreenProbeAtlasCoord]);
}

float GetScreenProbeDepth(uint2 ScreenProbeAtlasCoord)
{
	return GetScreenProbeDepth(ScreenProbeAtlasCoord, ScreenProbeSceneDepth);
}

float3 GetScreenProbeNormal(uint2 ScreenProbeAtlasCoord)
{
	return OctahedronToUnitVector(ScreenProbeWorldNormal[ScreenProbeAtlasCoord] * 2.0 - 1.0);
}

uint GetNumAdaptiveScreenProbes()
{
	return min(NumAdaptiveScreenProbes[0], MaxNumAdaptiveProbes);
}

uint2 GetAdaptiveProbeCoord(uint2 ScreenTileCoord, uint AdaptiveProbeListIndex)
{
	uint2 AdaptiveProbeCoord = uint2(AdaptiveProbeListIndex % ScreenProbeDownsampleFactor, AdaptiveProbeListIndex / ScreenProbeDownsampleFactor);
	//return ScreenTileCoord * ScreenProbeDownsampleFactor + AdaptiveProbeCoord;
	return AdaptiveProbeCoord * ScreenProbeViewSize + ScreenTileCoord;
}

uint GetNumScreenProbes()
{
	return NumUniformScreenProbes + GetNumAdaptiveScreenProbes();
}

uint EncodeScreenProbeData(uint2 ScreenProbeScreenPosition)
{
	return (ScreenProbeScreenPosition.x & 0xFFFF) | ((ScreenProbeScreenPosition.y & 0xFFFF) << 16);
}

uint2 DecodeScreenProbeData(uint EncodedProbeData)
{
	return uint2(EncodedProbeData & 0xFFFF, (EncodedProbeData >> 16) & 0xFFFF);
}

// Note this can return a screen position outside of the valid viewport, since probes can be placed off-screen due to DivideAndRoundUp
uint2 GetScreenProbeScreenPosition(uint ScreenProbeIndex)
{
	uint2 ScreenProbeAtlasCoord = uint2(ScreenProbeIndex % ScreenProbeViewSize.x, ScreenProbeIndex / ScreenProbeViewSize.x);
	uint2 ScreenProbeScreenPosition = ScreenProbeAtlasCoord * ScreenProbeDownsampleFactor + GetScreenTileJitter(SCREEN_TEMPORAL_INDEX) + View.ViewRectMinAndSize.xy;

	if (ScreenProbeIndex >= NumUniformScreenProbes)
	{
		ScreenProbeScreenPosition = DecodeScreenProbeData(AdaptiveScreenProbeData[ScreenProbeIndex - NumUniformScreenProbes]);
	}

	return ScreenProbeScreenPosition;
}

uint2 GetScreenTileCoord(uint2 ScreenProbeScreenPosition)
{
	return (ScreenProbeScreenPosition - GetScreenTileJitter(SCREEN_TEMPORAL_INDEX) - View.ViewRectMinAndSize.xy) / ScreenProbeDownsampleFactor;
}

uint2 GetUniformScreenProbeScreenPosition(uint2 ScreenTileCoord)
{
	uint2 ScreenJitter = GetScreenTileJitter(SCREEN_TEMPORAL_INDEX);
	uint2 ScreenProbeScreenPosition = min((uint2)(View.ViewRectMinAndSize.xy + ScreenTileCoord * ScreenProbeDownsampleFactor + ScreenJitter), (uint2)(View.ViewRectMinAndSize.xy + View.ViewRectMinAndSize.zw) - 1);
	return ScreenProbeScreenPosition;
}

float2 GetScreenTileCoordFromScreenUV(float2 ScreenUV, uint TemporalIndex)
{
	return (ScreenUV - (View.ViewRectMin.xy + GetScreenTileJitter(TemporalIndex) + 0.5f) * View.BufferSizeAndInvSize.zw) / (ScreenProbeDownsampleFactor * View.BufferSizeAndInvSize.zw);
}

float2 GetScreenUVFromScreenTileCoord(uint2 ScreenTileCoord)
{
	uint2 ScreenProbeScreenPosition = ScreenTileCoord * ScreenProbeDownsampleFactor + GetScreenTileJitter(SCREEN_TEMPORAL_INDEX) + View.ViewRectMinAndSize.xy;
	return (ScreenProbeScreenPosition + .5f) * View.BufferSizeAndInvSize.zw;
}

float2 GetScreenUVFromScreenProbePosition(uint2 ScreenProbeScreenPosition)
{
	// Probe ScreenUV can be outside of valid viewport, since probes are downsampled with DivideAndRoundUp
	float2 ScreenCoord = min((float2)ScreenProbeScreenPosition, View.ViewRectMin.xy + View.ViewSizeAndInvSize.xy - 1.0f);
	return (ScreenCoord + .5f) * View.BufferSizeAndInvSize.zw;
}

float3 GetWorldPositionFromScreenUV(float2 ScreenUV, float SceneDepth)
{
	float2 ScreenPosition = (ScreenUV - View.ScreenPositionScaleBias.wz) / View.ScreenPositionScaleBias.xy;
	float3 WorldPosition = mul(float4(ScreenPosition * SceneDepth, SceneDepth, 1), LWCHackToFloat(PrimaryView.ScreenToWorld)).xyz;
	return WorldPosition;
}

float3 GetTranslatedWorldPositionFromScreenUV(float2 ScreenUV, float SceneDepth)
{
	float2 ScreenPosition = (ScreenUV - View.ScreenPositionScaleBias.wz) / View.ScreenPositionScaleBias.xy;
	float3 TranslatedWorldPosition = mul(float4(ScreenPosition * SceneDepth, SceneDepth, 1), View.ScreenToTranslatedWorld).xyz;
	return TranslatedWorldPosition;
}

// This version ignores TAA jitter, use when sampling a history texture
float3 GetHistoryScreenPosition(float2 ScreenPosition, float2 ScreenUV, float DeviceZ)
{
	float3 HistoryScreenPosition = float3(ScreenPosition, DeviceZ);
	bool bIsDynamicPixel = false;

	{
		float4 ThisClip = float4(HistoryScreenPosition, 1);
		float4 PrevClip = mul(ThisClip, View.ClipToPrevClip); //<=== doesn't contain AA offsets

		float3 PrevScreen = PrevClip.xyz / PrevClip.w;
		float3 Velocity = HistoryScreenPosition - PrevScreen;
		float4 EncodedVelocity = GBufferVelocityTexture.SampleLevel(GlobalPointClampedSampler, ScreenUV, 0);
		bIsDynamicPixel = EncodedVelocity.x > 0.0;

		if (bIsDynamicPixel)
		{
			// Note: overwriting velocity, this only works if DeviceZ matches what's in the depth buffer
			Velocity = DecodeVelocityFromTexture(EncodedVelocity);
		}

		HistoryScreenPosition -= Velocity;
	}

	return HistoryScreenPosition;
}

// This version accounts for TAA jitter, use when comparing positions like calculating world space velocity
float3 GetHistoryScreenPositionIncludingTAAJitter(float2 ScreenPosition, float2 ScreenUV, float DeviceZ)
{
	float3 HistoryScreenPosition = GetHistoryScreenPosition(ScreenPosition - View.TemporalAAJitter.xy, ScreenUV, DeviceZ);
	HistoryScreenPosition.xy += View.TemporalAAJitter.zw;
	return HistoryScreenPosition;
}

float3 GetPrevTranslatedWorldPosition(float3 HistoryScreenPosition)
{
	float HistorySceneDepth = ConvertFromDeviceZ(HistoryScreenPosition.z);
	float3 PrevPositionTranslatedWorld = mul(float4(HistoryScreenPosition.xy * HistorySceneDepth, HistorySceneDepth, 1), View.PrevScreenToTranslatedWorld).xyz;
	float3 PreViewTranslationOffset = LWCToFloat(LWCSubtract(PrimaryView.PreViewTranslation, PrimaryView.PrevPreViewTranslation));
	float3 PrevTranslatedWorldPosition = PrevPositionTranslatedWorld + PreViewTranslationOffset;
	return PrevTranslatedWorldPosition;
}

uint2 GetTraceBufferCoord(uint2 ScreenProbeAtlasCoord, uint2 TraceTexelCoord)
{
	#define DEINTERLEAVED_TRACE_BUFFER_STORAGE 0
	#if DEINTERLEAVED_TRACE_BUFFER_STORAGE
		return TraceTexelCoord * ScreenProbeAtlasViewSize + ScreenProbeAtlasCoord;
	#else
		return ScreenProbeAtlasCoord * ScreenProbeTracingOctahedronResolution + TraceTexelCoord;
	#endif
}

RWTexture2D<uint> RWTraceHit;
RWTexture2D<float3> RWTraceRadiance;
Texture2D<uint> TraceHit;

float GetProbeMaxHitDistance()
{
	return MaxHalfFloat;

}

#define PROBE_RAY_DISTANCE_ENCODE_SCALE 0.1f

uint EncodeProbeRayDistance(float HitDistance, bool bHit, bool bMoving)
{
	HitDistance = max(HitDistance, 0.0f);

	uint EncodedRay = 0;
	EncodedRay = clamp(uint(HitDistance * PROBE_RAY_DISTANCE_ENCODE_SCALE + 0.5f), 0, 0x3FFFFFFF);
	EncodedRay |= bHit ? (1 << 30) : 0;
	EncodedRay |= bMoving ? (1 << 31) : 0;
	return EncodedRay;
}

float DecodeProbeRayDistance(uint Encoded, out bool bHit, out bool bMoving)
{
	bHit = (Encoded & (1 << 30)) != 0;
	bMoving = (Encoded & (1 << 31)) != 0;
	return (Encoded & 0x3FFFFFFF) / PROBE_RAY_DISTANCE_ENCODE_SCALE;
}

float DecodeProbeRayDistance(uint Encoded, out bool bHit)
{
	bool bMoving;
	return DecodeProbeRayDistance(Encoded, bHit, bMoving);
}

float DecodeProbeRayDistance(uint Encoded)
{
	bool bHit;
	bool bMoving;
	return DecodeProbeRayDistance(Encoded, bHit, bMoving);
}

uint EncodeScreenProbeSpeed(float ProbeSpeed, bool bTwoSidedFoliage)
{
	return f32tof16(ProbeSpeed) | (bTwoSidedFoliage ? 0x8000 : 0);
}

bool GetScreenProbeIsTwoSidedFoliage(uint2 ScreenProbeAtlasCoord)
{
	uint Encoded = ScreenProbeWorldSpeed.Load(int3(ScreenProbeAtlasCoord, 0));
	return (Encoded & 0x8000) != 0;
}

float GetScreenProbeSpeed(uint2 ScreenProbeAtlasCoord)
{
	uint Encoded = ScreenProbeWorldSpeed.Load(int3(ScreenProbeAtlasCoord, 0));
	return f16tof32(Encoded & 0x7FFF);
}

bool IsTraceMoving(float3 ProbeWorldPosition, float ProbeSceneDepth, uint2 ScreenProbeAtlasCoord, float3 HitWorldPosition, float3 HitWorldVelocity)
{
	//@todo - for pixels that use the velocity texture in GetHistoryScreenPosition, velocities transformed to world space are too inaccurate to use for a dis-occlusion test
	// See DEBUG_VISUALIZE_PROBE_WORLD_SPEED
#define VELOCITY_IS_ACCURATE 0
#if VELOCITY_IS_ACCURATE
	float3 ProbeWorldVelocity = ScreenProbeWorldVelocity.Load(int3(ScreenProbeAtlasCoord, 0)).xyz;
	float VelocityDampening = lerp(1, .1f, saturate(ProbeSceneDepth / 10000.0f));
	float3 ProbeToHit = HitWorldPosition - ProbeWorldPosition;
	float3 PrevProbeToPrevHit = HitWorldPosition - HitWorldVelocity * VelocityDampening - (ProbeWorldPosition - ProbeWorldVelocity * VelocityDampening);
	float3 CosAngle = dot(ProbeToHit, PrevProbeToPrevHit) / max(length(ProbeToHit) * length(PrevProbeToPrevHit), .0001f);
	float CosProbeTraceVelocityAngleThreshold = cos(1.0f * (float)PI / 180.0f);
	return CosAngle < CosProbeTraceVelocityAngleThreshold;
#else
	float ProbeWorldSpeed = GetScreenProbeSpeed(ScreenProbeAtlasCoord);

	return abs(ProbeWorldSpeed - length(HitWorldVelocity)) / max(ProbeSceneDepth, 100.0f) > RelativeSpeedDifferenceToConsiderLightingMoving;
#endif
}

Texture2D<float> ScreenProbeMoving;

float GetScreenProbeMoving(uint2 ScreenProbeAtlasCoord)
{
	return ScreenProbeMoving[ScreenProbeAtlasCoord];
}

float EncodeProbeHitDistanceForFiltering(float HitDistance)
{
	// Encode one negative value to indicate invalid ray
	return sqrt(HitDistance / GetProbeMaxHitDistance()) * 254.0f / 255.0f + 1.0f / 255.0f;
}

float DecodeProbeHitDistanceForFiltering(float Encoded)
{
	float Linear = Encoded * Encoded * GetProbeMaxHitDistance();
	return (Linear - 1.0f / 255.0f) * 255.0f / 254.0f;
}

// Stores a packed ray info for each tracing shader lane storing the direction and mip level of the ray to trace
Texture2D<uint> StructuredImportanceSampledRayInfosForTracing;
uint MaxImportanceSamplingOctahedronResolution;
uint ScreenProbeBRDFOctahedronResolution;

#define INVALID_TRACING_COORD 0xFE

uint PackRayInfo(uint2 TexelCoord, uint Level)
{
	// Pack in 16 bits
	return (TexelCoord.x & 0x3F) | ((TexelCoord.y & 0x3F) << 6) | ((Level & 0xF) << 12);
}

void UnpackRayInfo(uint RayInfo, out uint2 TexelCoord, out uint Level)
{
	TexelCoord.x = RayInfo & 0x3F;
	TexelCoord.y = (RayInfo >> 6) & 0x3F;
	Level = (RayInfo >> 12) & 0xF;
}

void GetProbeTracingUV(
	uint2 ScreenProbeAtlasCoord,
	uint2 TracingTexelCoord,
	float2 ProbeTexelCenter,
	float NumSupersamples,
	out float2 ProbeUV,
	out float ConeHalfAngle)
{
#if STRUCTURED_IMPORTANCE_SAMPLING
	uint2 GlobalTraceCoord = GetTraceBufferCoord(ScreenProbeAtlasCoord, TracingTexelCoord);
	uint RayInfo = StructuredImportanceSampledRayInfosForTracing[GlobalTraceCoord];
	uint2 RayTexelCoord;
	uint RayLevel;
	UnpackRayInfo(RayInfo, RayTexelCoord, RayLevel);

	uint MipSize = MaxImportanceSamplingOctahedronResolution >> RayLevel;
	float InvSupersampledMipSize = 1.0f / (MipSize * NumSupersamples);
	ProbeUV = (RayTexelCoord * NumSupersamples + ProbeTexelCenter) * InvSupersampledMipSize;
	ConeHalfAngle = acosFast(1.0f - 1.0f * InvSupersampledMipSize * InvSupersampledMipSize);

#else
	ProbeUV = (TracingTexelCoord * NumSupersamples + ProbeTexelCenter) / float(ScreenProbeTracingOctahedronResolution * NumSupersamples);
	// Evenly distributing the sphere solid angle among all cones
	ConeHalfAngle = acosFast(1.0f - 1.0f / (float)(ScreenProbeTracingOctahedronResolution * ScreenProbeTracingOctahedronResolution * NumSupersamples * NumSupersamples));
#endif
}

Texture2D OctahedralSolidAngleTexture;
float OctahedralSolidAngleTextureResolutionSq;

float OctahedralSolidAngleLUT(float2 UV, float Resolution)
{
	return OctahedralSolidAngleTexture.SampleLevel(GlobalBilinearClampedSampler, UV, 0).x * OctahedralSolidAngleTextureResolutionSq / (Resolution * Resolution);
}

StructuredBuffer<uint> CompactedTraceTexelAllocator;
StructuredBuffer<uint2> CompactedTraceTexelData;

uint2 EncodeTraceTexel(uint ScreenProbeIndex, uint2 TraceTexelCoord, float TraceHitDistance)
{
	return uint2(
		(ScreenProbeIndex & 0xFFFFF) | ((TraceTexelCoord.x & 0x1F) << 20) | ((TraceTexelCoord.y & 0x1F) << 25),
		asuint(TraceHitDistance));
}

void DecodeTraceTexel(uint2 TraceTexelData, inout uint ScreenProbeIndex, inout uint2 TraceTexelCoord, inout float TraceHitDistance)
{
	ScreenProbeIndex = TraceTexelData.x & 0xFFFFF;
	TraceTexelCoord.x = (TraceTexelData.x >> 20) & 0x1F;
	TraceTexelCoord.y = (TraceTexelData.x >> 25) & 0x1F;
	TraceHitDistance = asfloat(TraceTexelData.y);
}

Texture2D<uint> LightingChannelsTexture;

bool HasDistanceFieldRepresentation(float2 ScreenUV)
{
	return (LightingChannelsTexture[(int2)(ScreenUV * View.BufferSizeAndInvSize.xy)] & (1 << LIGHTING_CHANNELS_TEXTURE_DISTANCE_FIELD_REPRESENTATION_BIT)) != 0;
}
